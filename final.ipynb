{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" \n1. Join data by student ID. ","metadata":{}},{"cell_type":"code","source":"library(readxl)\nlibrary(dplyr)\nlibrary(tidyverse)\nlibrary(rattle)\nlibrary(rpart.plot)\nlibrary(RColorBrewer)\nlibrary(xgboost)\nlibrary(caret)\nlibrary(leaps)\n\nfall_2011_SP <- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Progress Data/Fall 2011_SP.csv\")\nfall_2012_SP <- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Progress Data/Fall 2012_SP.csv\")\nfall_2013_SP <- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Progress Data/Fall 2013_SP.csv\")\nfall_2014_SP <- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Progress Data/Fall 2014_SP.csv\")\nfall_2015_SP <- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Progress Data/Fall 2015_SP.csv\")\nfall_2016_SP <- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Progress Data/Fall 2016_SP.csv\")\nSpring_2012_SP <- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Progress Data/Spring 2012_SP.csv\")\nSpring_2013_SP <- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Progress Data/Spring 2013_SP.csv\")\nSpring_2014_SP <- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Progress Data/Spring 2014_SP.csv\")\nSpring_2015_SP <- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Progress Data/Spring 2015_SP.csv\")\nSpring_2016_SP <- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Progress Data/Spring 2016_SP.csv\")\nSpring_2017_SP <- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Progress Data/Spring 2017_SP.csv\")\nSum_2012_SP <- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Progress Data/Sum 2012.csv\")\nSum_2013_SP <- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Progress Data/Sum 2013.csv\")\nSum_2014_SP <- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Progress Data/Sum 2014.csv\")\nSum_2015_SP <- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Progress Data/Sum 2015.csv\")\nSum_2016_SP <- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Progress Data/Sum 2016.csv\")\nSum_2017_SP <- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Progress Data/Sum 2017.csv\")\nFall_2011_ST <- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Static Data/Fall 2011_ST.csv\")\nFall_2012_ST <- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Static Data/Fall 2012.csv\")\nFall_2013_ST<- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Static Data/Fall 2013.csv\")\nFall_2014_ST<- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Static Data/Fall 2014.csv\")\nFall_2015_ST<- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Static Data/Fall 2015.csv\")\nFall_2016_ST<- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Static Data/Fall 2016.csv\")\nSpring_2012_ST<- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Static Data/Spring 2012_ST.csv\")\nSpring_2013_ST<- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Static Data/Spring 2013.csv\")\nSpring_2014_ST<- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Static Data/Spring 2014.csv\")\nSpring_2015_ST<- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Static Data/Spring 2015.csv\")\nSpring_2016_ST<- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Static Data/Spring 2016.csv\")\nFASFA <- read_excel(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Student Financial Aid Data/2011-2017_Cohorts_Financial_Aid_and_Fafsa_Data.xlsx\")\nFASFA <- rename(FASFA, StudentID = `ID with leading`)\nFASFA$StudentID <- as.integer(FASFA$StudentID)\n\nFASFA$Loans <- rowSums(FASFA[, c(\"2012 Loan\", \"2013 Loan\", \"2014 Loan\", \"2015 Loan\", \"2016 Loan\", \"2017 Loan\")], na.rm = TRUE)\nFASFA$Scholarships <- rowSums(FASFA[, c(\"2012 Scholarship\", \"2013 Scholarship\", \"2014 Scholarship\", \"2015 Scholarship\", \"2016 Scholarship\", \"2017 Scholarship\")], na.rm = TRUE)\nFASFA$Income <- FASFA$`Adjusted Gross Income` + FASFA$`Parent Adjusted Gross Income`\nFASFA$Grant <- rowSums(FASFA[, c(\"2012 Grant\", \"2013 Grant\", \"2014 Grant\", \"2015 Grant\", \"2016 Grant\", \"2017 Grant\")], na.rm = TRUE)\nFASFA$Workstudy <- rowSums(FASFA[, c(\"2012 Work/Study\", \"2013 Work/Study\", \"2014 Work/Study\", \"2015 Work/Study\", \"2016 Work/Study\", \"2017 Work/Study\")], na.rm = TRUE)\n\nFASFA$Income[is.na(FASFA$Income)] <- mean(FASFA$Income, na.rm = TRUE)\n\n# Join the data by student ID\nSP<- rbind(fall_2011_SP, fall_2012_SP, fall_2013_SP, fall_2014_SP, fall_2015_SP, fall_2016_SP, Spring_2012_SP, Spring_2013_SP, Spring_2014_SP, Spring_2015_SP, Spring_2016_SP, Spring_2017_SP, Sum_2012_SP, Sum_2013_SP, Sum_2014_SP,Sum_2015_SP, Sum_2016_SP, Sum_2017_SP)\nST<- rbind(Fall_2011_ST,Fall_2012_ST,Fall_2013_ST,Fall_2014_ST,Fall_2015_ST,Fall_2016_ST,Spring_2012_ST,Spring_2013_ST,Spring_2014_ST, Spring_2015_ST,Spring_2016_ST)\n\nStudent_ID <- inner_join(SP, ST, by=\"StudentID\")\nStudent_ID <- inner_join(Student_ID, FASFA, by = \"StudentID\")\n\nStudent_ID$Race <- rowSums(Student_ID[, c(\"Hispanic\", \"AmericanIndian\", \"Asian\", \"Black\", \"NativeHawaiian\", \"White\", \"TwoOrMoreRace\")], na.rm = TRUE)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T00:13:37.968637Z","iopub.execute_input":"2023-02-27T00:13:37.972913Z","iopub.status.idle":"2023-02-27T00:13:46.404414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Clean data and perform feature engineering.","metadata":{}},{"cell_type":"code","source":"# check for missing values\ncolSums(is.na(Student_ID))\n\n# remove columns with missing values\nStudent_ID <- Student_ID[, colSums(is.na(Student_ID)) == 0]\n\n# Remove duplicates\nStudent_ID <- Student_ID[!duplicated(Student_ID$StudentID),]\n\n# remove duplicates based on the \"id\" column\nStudent_ID <- distinct(Student_ID, StudentID, .keep_all = TRUE)\n\n# identify columns with only 0 values\nzero_cols <- sapply(Student_ID, function(x) all(x == 0))\n\n# remove identified columns\nStudent_ID <- Student_ID[, !zero_cols]\n\ncomplete.cases(Student_ID)\n# print the result\nStudent_ID","metadata":{"execution":{"iopub.status.busy":"2023-02-27T00:13:46.408327Z","iopub.execute_input":"2023-02-27T00:13:46.457576Z","iopub.status.idle":"2023-02-27T00:13:47.725028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3. Separate the data into training and test based on test IDs I have provided in testids.csv file. We will call the test dataset Kaggletest just to differentiate it from other test datasets we will create later in step 5. Set the kaggletest dataset aside until step 6.","metadata":{}},{"cell_type":"code","source":"test_ids <- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/Student Retention Challenge Data/Test Data/TestIDs.csv\", header = TRUE)\ntest1 <- test_ids$StudentID\ntrain1 <- Student_ID[!Student_ID$StudentID %in% test_ids$StudentID,]\nKaggletest <- Student_ID[Student_ID$StudentID %in% test_ids$StudentID,]","metadata":{"execution":{"iopub.status.busy":"2023-02-27T00:13:47.728688Z","iopub.execute_input":"2023-02-27T00:13:47.731073Z","iopub.status.idle":"2023-02-27T00:13:47.785844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"4. Add the Dropout labels column to the train dataset by joining to the data in droppoutTrainlabels.csv file.","metadata":{}},{"cell_type":"code","source":"# read the dropoutTrainlabels.csv file\ndropout_labels <- read.csv(\"/kaggle/input/finc-530-student-dropout-prediction-challenge/DropoutTrainLabels.csv\")\n\n# merge the train and dropout labels dataframes\ntrain1 <- merge.data.frame(train1, dropout_labels, by = \"StudentID\")","metadata":{"execution":{"iopub.status.busy":"2023-02-27T00:13:47.789493Z","iopub.execute_input":"2023-02-27T00:13:47.791702Z","iopub.status.idle":"2023-02-27T00:13:47.890430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"5. Fit various models to the training dataset by going through the usual process of further splitting this dataset into train and test and measuring performance.","metadata":{}},{"cell_type":"code","source":"# Convert Dropout to a factor variable if necessary\ncolnames(train1) <- make.names(colnames(train1))\ntrain1 <- train1[, c(\"StudentID\", \"Cohort.x\",\"AcademicYear\", \"Major1\", \"TermGPA\", \"CumGPA\",\"RegistrationDate\",\"NumColCredAttemptTransfer\", \"NumColCredAcceptTransfer\", \"Loans\", \"Scholarships\",\"Grant\",\"Income\", \"Dropout\")]\ntrain1$Dropout <- as.factor(train1$Dropout)\nintrain <- createDataPartition(train1$Dropout, p = 0.5, list = FALSE)\ntest1 <- train1[-intrain,]\n# Create a train control object for 10-fold cross validation\ntrctrl <- trainControl(method = \"cv\", number = 10, )","metadata":{"execution":{"iopub.status.busy":"2023-02-27T00:13:47.894700Z","iopub.execute_input":"2023-02-27T00:13:47.896819Z","iopub.status.idle":"2023-02-27T00:13:47.952760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tree fit\ntree_fit <- train(Dropout ~ ., data = train1, method = \"rpart\",\n                  trControl=trctrl)\n\n#To see the tuned complexity parameter (Gini Coeff)\ntree_fit$bestTune\n#To see the tree splits\ntree_fit$finalModel\n#Plot complexity parameter tuning runs\nplot(tree_fit)\n#Plot the tree\n\nfancyRpartPlot(tree_fit$finalModel)\n#Predict\npredictions <- predict(tree_fit, newdata = test1)\n\n#Performance metrics\n#Calculate Mean Square Error (MSE)\nmean(( predictions - test1$Dropout)^2)\n#To see the importance of the variables\ntreeImp <- varImp(tree_fit, scale = TRUE)\ntreeImp\nplot(treeImp)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-27T00:13:47.956408Z","iopub.execute_input":"2023-02-27T00:13:47.958612Z","iopub.status.idle":"2023-02-27T00:13:53.772634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Random Forest\n\n#Fit the random forest (method = \"rf\"). Set importance = TRUE to have the variable importance calculated.\n#Parameter mtry in the train function lets you set how many variables are considered at each split\nforest_fit <- train(Dropout ~., data = train1, method = \"rf\",\n                    trControl = trctrl, preProcess=c('scale', 'center'))\n\n#To see model details\nforest_fit\n#To see the tuned mtry parameter.  Mtry is the number of randomly selected predictors\nforest_fit$bestTune\n#To see the the % variance explained\nforest_fit$finalModel\n#Plot complexity parameter tuning runs\nplot(forest_fit)\n#Predict\npredictions <- predict(forest_fit, newdata = test1)\n\n#Calculate MSE\nmean(( predictions - test1$Dropout)^2)\n#To see the importance of the variables\nforestImp <- varImp(forest_fit)\nforestImp\nplot(forestImp)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T00:13:53.774878Z","iopub.execute_input":"2023-02-27T00:13:53.776267Z","iopub.status.idle":"2023-02-27T00:21:56.867532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert target to numeric\ntr_label <- as.numeric(train1$Dropout) - 1\nts_label <- as.numeric(test1$Dropout) - 1\n\n# One hot encode predictor variables to convert categorical variables to numeric\nm_train <- model.matrix(~.+0, data = train1[, -5]) \nm_test <- model.matrix(~.+0, data = test1[, -5])\n\ndtrain <- xgb.DMatrix(data = m_train, label = tr_label) \ndtest <- xgb.DMatrix(data = m_test, label = ts_label)\n\nparams <- list(\n  booster = \"gbtree\",\n  objective = \"multi:softmax\",\n  num_class = 3,\n  eta = 0.3,\n  gamma = 0,\n  max_depth = 2,\n  min_child_weight = 1, \n  subsample = 1,\n  colsample_bytree = 1\n)\n\nxgbcv <- xgb.cv(\n  params = params,\n  data = dtrain,\n  nrounds = 1000, \n  nfold = 5,\n  showsd = T,\n  stratified = T, \n  print_every_n = 10,\n  early_stop_rounds = 20, \n  maximize = F\n)\n\nbst <- xgb.train(params = params, data = dtrain, nrounds = 100)\n\npred <- predict(bst, dtest)\npred <- ifelse(pred > 0.5, 1, 0)\npred <- as.factor(pred)\n\nts_label <- as.factor(ts_label)\n\nconfusionMatrix(pred, ts_label)\n\nmat <- xgb.importance(feature_names = colnames(m_train), model = bst)\nxgb.plot.importance(importance_matrix = mat)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-27T00:21:56.870025Z","iopub.execute_input":"2023-02-27T00:21:56.871390Z","iopub.status.idle":"2023-02-27T00:22:20.651584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Bagging\n#No tuning parameters supported\nbag_fit <- train(Dropout ~., data = train1, method = \"treebag\",\n                    trControl=trctrl)\nbag_fit\npredictions <- predict(bag_fit, newdata = test1)\n\nmean(( predictions - test1$Dropout)^2)\n#To see the importance of the variables\nbagImp <- varImp(bag_fit, scale=TRUE)\nbagImp\nplot(bagImp)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T00:22:20.653857Z","iopub.execute_input":"2023-02-27T00:22:20.655118Z","iopub.status.idle":"2023-02-27T00:23:33.320908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fit the SVM model to training data\n#svmRadial uses the Radial Kernel.  \n#You can explicitly specify the cost parameter by using the C = option \n#and the gamma (sigma) parameter using the sigma = option\nmodSVMFit <- train(Dropout ~ .,method=\"svmRadial\",sigma =.2,trControl=trctrl,data=train1)\n#See model fit details\nmodSVMFit$finalModel\n#See the tuning parametrs used (cost C, and sigma of the radial kernel function)\nmodSVMFit$bestTune\n#See the results details by each optimization run\nmodSVMFit$results\n#Predict test dataset\nSVMpredict <- predict(modSVMFit,test1)\n\nconfusionMatrix(SVMpredict,test1$Dropout)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T00:23:33.323232Z","iopub.execute_input":"2023-02-27T00:23:33.324604Z","iopub.status.idle":"2023-02-27T00:27:08.855381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"6. Predict using the Kaggletest dataset. This will result in a column with 1s and 0s in the prediction object you create.","metadata":{}},{"cell_type":"code","source":"# Predict using the Kaggletest dataset\npredictions <- predict(forest_fit, newdata = Kaggletest)\n\npredictions_binary <- as.integer(predictions == levels(predictions)[2])\n\npredictions_binary","metadata":{"execution":{"iopub.status.busy":"2023-02-27T00:27:08.858757Z","iopub.execute_input":"2023-02-27T00:27:08.860881Z","iopub.status.idle":"2023-02-27T00:27:09.017019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"7. Combine this prediction column with the student ID column in the kaggletest dataframe and create a new data frame that has two columns Student ID and Dropout","metadata":{}},{"cell_type":"code","source":"nrow(Kaggletest)\n# create a new dataframe with Student ID and Dropout columns\nnew_df <- data.frame(StudentID = Kaggletest$StudentID, Dropout = predictions_binary)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T00:27:09.020435Z","iopub.execute_input":"2023-02-27T00:27:09.022355Z","iopub.status.idle":"2023-02-27T00:27:09.041821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"8. Write the dataframe created above to a csv file and submit to Kaggle. Note: the submission file should look exactly like the sample submission file I have provided. Once you submit to Kaggle you will get the accuracy (F1 measure) that determines your position on the leaderboard.\n\n","metadata":{}},{"cell_type":"code","source":"# write the result dataframe to a csv file\nwrite.csv(new_df, \"submission.csv\", row.names = FALSE)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T00:27:09.045205Z","iopub.execute_input":"2023-02-27T00:27:09.046913Z","iopub.status.idle":"2023-02-27T00:27:09.062685Z"},"trusted":true},"execution_count":null,"outputs":[]}]}